---
layout: ../../layouts/MarkdownPostLayout.astro
title: '从零构建个人博客：网站搭建记录'
pubDate: 2025-11-18
lastUpdateDate: 2025-11-19
tags: [WSL, Astro, Netlify, Fontsource, tailwindcss]
---

# 1. Background

**目标：**构建一个可以持续增量学习、适应时间变化的识别记忆模型。

**挑战：**

1. 可持续增量学习：
    1. 之前的研究
        1. 要么当作固定数据集；
        2. 要么不考虑“记忆库随时间不停扩张“。
    2. 要求学习新的记忆时不用反复访问所有旧数据。
    
    故要求结构上要可扩展（scalable），不会被组合爆炸撑死。
    
2. 经验是多维、多类别、上下文丰富的：
    1. 属性之间不仅有 pairwise 关系，还有高阶关系（三元、四元…）。
3. 作者希望识别记忆模型要：
    1. 熟悉度判断的 ROC 像人；
    2. 能做 pattern completion（从部分信息补全出完整模式）。

# 2. Preliminary

1. **事件表示 → 超图**
    
    ![image.png](attachment:7a51d53b-08c6-4baa-8043-93d9323fc220:image.png)
    
    - 一次事件实例 $X = {x_1,\dots,x_d}$：
        - 每个节点 $x_i$ 是一个属性值（时间、地点、人、活动…）。
    - 把 $X$ 拆成多个子集，每个子集是一个超边（hyperedge）：
        - 超边 = $k$ 个节点的组合 → “$k$ 阶边”；
        - 同一个节点可以出现在多条超边里。
    - 一个 event == 一个小 hypergraph
    
    ![image.png](attachment:9db1302d-4f79-4209-99a0-6014d5c20bfa:image.png)
    
    对 event 做 sampling 时会将相邻的超边通过 link 连接。
    
2. **links（链接）**
    
    ![The solid rectangles indicate edges with different node sizes. The dotted lines indicate the links between two edges acquired from the input data.](attachment:f0ec067a-b431-4aec-80bc-215ef8eb051f:image.png)
    
    The solid rectangles indicate edges with different node sizes. The dotted lines indicate the links between two edges acquired from the input data.
    
    - 在超边之间建立链接，每条链接带一个权重；
    - 他们让“相邻的超边”之间全部互联，于是这些边在图中形成一个环或链。
        - 事件的属性是「无序的」 → 用环状结构
            - 例如：时间段、地点编号、类型、应用、联系人
            - 这些属性的特点是：它们之间没有先后顺序，也没有“第一个属性 / 最后一个属性”之说。
            - 在这种情况下：所有属性都是并列关系，没有方向，也不该谁指向谁。
        - 数据是「有序的」 → 用线状结构
            - 例如：单词由字母组成：CAT → C-A-T 句子由词构成，有顺序、时间序列：x₁, x₂, x₃、动作序列：拿起 → 走 → 放下
            - 这些数据的特点是：元素之间存在天然的先后顺序，不能随便换。
- 模型参数：
    1. 边阶 $k$（edge order）：
        - 固定 $k$：所有超边都是 $k$ 阶；
        - 变 $k$：混合 2 阶、3 阶、… 多尺度表达。
    2. 组合方式（combinational type）：哪些属性组合成一条超边
        - 按属性顺序取相邻（滑动窗口）；
        - 或打乱/随机组合。
        - 因为属性的排列顺序未必反映真实因果，所以如何组合属性很关键。
    3. 重复编码次数（study duration）：
        - 同一实例编码多次，相当于“学了很多遍”；
        - 影响链接权重、网络密度 → 影响熟悉度 & 补全性能。
    4. 连通性（connectivity）：
        - 平均每条边的链接数；
        - 越密：越容易补全，也越容易误认新模式为旧。

# 3. Main Procedure

![The upper arrows (dot lines) represent a process of familiarity judgment from complete input data. In contrast, the lower arrows (solid lines) show pattern completion from partial input data.](attachment:b90f624b-86db-4e2c-89a1-5f5b5551b1f3:image.png)

The upper arrows (dot lines) represent a process of familiarity judgment from complete input data. In contrast, the lower arrows (solid lines) show pattern completion from partial input data.

根据输入是否缺失值，判断的流程有两种：

1. 完整输入（无 missing）
    - 做单纯的 Old/New 判定。
2. 部分输入（有 missing）
    - 执行另一个流程（pattern completion）

## 3.1 完整输入

1. **Sampling（采样）**
    - 给一个新事件实例 $X=\{x_1,…,x_6\}$：按预设规则，把它切成若干 $k$ 阶超边：比如选 $\{x_1,x_2,x_3\}, \{x_3,x_4\}, \{x_2,x_5,x_6\}$ 之类。
2. **Connecting（连接）**
    
    对每条新超边做两件事：
    
    1. 查内存里有没有相同的超边：（使用 **familiarity judgment**）
        - 有 → 复用这条已有超边；
        - 没有 → 创建一条新超边节点。
    2. 对这次事件内部所有相关超边，相互之间建立/强化链接，表示“它们在同一个事件里共现过”。
3. **Weighting（赋权）**
    - 统计某两个边之间一共被连接了多少次，同一事件中的超边两两之间 link 计数 $l_{ij}$++；
    - 用 sigmoid 把 $l_{ij}$ 映射成权重 $\phi_{ij} \in (0,1)$：
        - 前期几次共现影响大，后期渐渐饱和。

### **Familiarity Judgment**

1. **Activation（用包含关系匹配边，不需要完全包含）**
    - 对每个 probe 边 $E_i$，与记忆边 $E_m$ 比较：
        - 至少有一个相同值；
        - 没有“冲突值”；
        - 缺失值不算 mismatch。
2. **判断（Judgment）：有没有“闭环/闭链”**
    
    ![Top graphs ((a)–(d)) represent ring-type networks and bottom graphs ((e)–(h)) represent line-type networks. Among the graphs, (a), (b), (e), and (f) contain a fully connected links, which are judged as old or familiar.](attachment:352d8512-58a1-40cb-9df4-7eebe998b022:image.png)
    
    Top graphs ((a)–(d)) represent ring-type networks and bottom graphs ((e)–(h)) represent line-type networks. Among the graphs, (a), (b), (e), and (f) contain a fully connected links, which are judged as old or familiar.
    
    - 看被激活的边在网络里是否通过链接构成一个完整闭环（ring）或闭链（line），覆盖所有相关维度：
        - 有完整闭环 → 认为这是曾经编码过的组合 → 判 old；
        - 否则 → 判 new。

## 3.2 部分输入

### Pattern Completion

从残缺信息恢复原始完整信息。

1. **部分输入的激活规则**
    - 仍然使用 $δ(Ei, Em)$ 的“包含关系”规则：
        - 不能出现冲突值；
        - 至少一个值必须匹配。
2. **从激活边组合出完整模式**
    - 部分输入（partial cue）会激活所有 **包含某些匹配属性** 的超边。
    - 如果这些边能在网络里组成一个自洽的闭环/闭链 →
        - 这个环/链就对应一套**完整事件**，
        - 其中包含了原来输入中缺失的属性值 → 完成补全。
3. **补全性能的两个指标**
    - **Completeness（完备性）**：
        - 是否成功找到一条完整连接（闭环）；
        - 换句话说：是否能补全出至少一个完整事件。
    - **Expectation（期望度）**：论文中该实验数据小于 <50%，在 20% 附近比较多。
        - 在补出的完整事件中，是否有一个**刚好等于原始完整数据**（实验里知道 ground truth）；
        - 用来评估：正确性。
4. **与结构参数的关系**
    - 和熟悉度一样：
        - 边阶 k、组合方式、连通性都会影响 Completeness & Expectation；
    - 网络太稀：补不上 → Completeness 低；
    - 网络太密：随便都能连上，但可能补错 → FP/Expectation 问题。

# 4. 复现实验记录

https://github.com/Yangliduo-Lai/hypergraph-recognition-memory-reproduction

## 5.1 事件的扰动带来的影响

从事件库里抽 5 个不同的事件：

- 第 1 个事件：先输入原始 E，然后做 50 次 1 维扰动得到 E`；
- 第 2 个事件：先输入原始 E，然后做 50 次 2 维扰动得到 E`；
- …
- 第 5 个事件：先输入原始 E，然后做 50 次 5 维扰动得到 E`。

HyperMemory 一直是同一个，顺序看完整个“终身经历”。

- 观察：
    - E → new（写入记忆）
    - E' → 有多少超边能匹配？有环吗？`is_old` 倾向如何？

$$
edge\_coverage=\frac{\text{事件超图中有匹配的超边数}}{\text{事件超图总超边数}}
$$

---

1. **k=1：非常稳定的“old”，完全当成同一个事件**
    - **结果**
        
        ![Figure_1.png](attachment:cbbed012-4847-49ee-b8fb-61cdb8d396d7:Figure_1.png)
        
        | step | group | k | is_old | edge_cov | has_cycle | n_active | mem_edges | mem_links |
        | --- | --- | --- | --- | --- | --- | --- | --- | --- |
        | 1 | 1 | 0 | False | 0.00 | False | 0 | 8 | 8 |
        | 2 | 1 | 1 | True | 1.00 | True | 8 | 8 | 8 |
        | 3 | 1 | 1 | True | 1.00 | True | 8 | 8 | 8 |
        | 4 | 1 | 1 | True | 1.00 | True | 8 | 8 | 8 |
        | 5 | 1 | 1 | True | 1.00 | True | 8 | 8 | 8 |
        | 6 | 1 | 1 | True | 1.00 | True | 8 | 8 | 8 |
        | 7 | 1 | 1 | True | 1.00 | True | 8 | 8 | 8 |
        | 8 | 1 | 1 | False | 0.88 | False | 8 | 9 | 11 |
        | 9 | 1 | 1 | True | 1.00 | True | 8 | 9 | 11 |
        | 10 | 1 | 1 | True | 1.00 | True | 8 | 9 | 11 |
        | 11 | 1 | 1 | True | 1.00 | True | 7 | 9 | 11 |
        | 12 | 1 | 1 | True | 1.00 | True | 8 | 9 | 11 |
        | 13 | 1 | 1 | True | 1.00 | True | 8 | 9 | 11 |
        | 14 | 1 | 1 | True | 1.00 | True | 7 | 9 | 11 |
        | 15 | 1 | 1 | True | 1.00 | True | 9 | 9 | 11 |
        | 16 | 1 | 1 | True | 1.00 | True | 8 | 9 | 11 |
        | 17 | 1 | 1 | True | 1.00 | True | 9 | 9 | 11 |
        | 18 | 1 | 1 | True | 1.00 | True | 8 | 9 | 11 |
        | 19 | 1 | 1 | True | 1.00 | True | 9 | 9 | 11 |
        | 20 | 1 | 1 | True | 1.00 | True | 8 | 9 | 11 |
        | 21 | 1 | 1 | True | 1.00 | True | 9 | 9 | 11 |
        | 22 | 1 | 1 | True | 1.00 | True | 9 | 9 | 11 |
        | 23 | 1 | 1 | True | 1.00 | True | 9 | 9 | 11 |
        | 24 | 1 | 1 | True | 1.00 | True | 8 | 9 | 11 |
        | 25 | 1 | 1 | True | 1.00 | True | 9 | 9 | 11 |
        | 26 | 1 | 1 | True | 1.00 | True | 9 | 9 | 11 |
        | 27 | 1 | 1 | True | 1.00 | True | 8 | 9 | 11 |
        | 28 | 1 | 1 | True | 1.00 | True | 8 | 9 | 11 |
        | 29 | 1 | 1 | True | 1.00 | True | 9 | 9 | 11 |
        | 30 | 1 | 1 | True | 1.00 | True | 9 | 9 | 11 |
        | 31 | 1 | 1 | True | 1.00 | True | 9 | 9 | 11 |
        | 32 | 1 | 1 | True | 1.00 | True | 8 | 9 | 11 |
        | 33 | 1 | 1 | True | 1.00 | True | 8 | 9 | 11 |
        | 34 | 1 | 1 | False | 0.75 | False | 9 | 11 | 15 |
        | 35 | 1 | 1 | True | 1.00 | True | 10 | 11 | 15 |
        | 36 | 1 | 1 | True | 1.00 | True | 11 | 11 | 15 |
        | 37 | 1 | 1 | True | 1.00 | True | 10 | 11 | 15 |
        | 38 | 1 | 1 | True | 1.00 | True | 10 | 11 | 15 |
        | 39 | 1 | 1 | False | 0.88 | False | 10 | 12 | 18 |
        | 40 | 1 | 1 | False | 0.88 | False | 11 | 13 | 20 |
        | 41 | 1 | 1 | True | 1.00 | True | 13 | 13 | 20 |
        | 42 | 1 | 1 | True | 1.00 | True | 8 | 13 | 20 |
        | 43 | 1 | 1 | True | 1.00 | True | 11 | 13 | 20 |
        | 44 | 1 | 1 | True | 1.00 | True | 12 | 13 | 20 |
        | 45 | 1 | 1 | True | 1.00 | True | 11 | 13 | 20 |
        | 46 | 1 | 1 | True | 1.00 | True | 8 | 13 | 20 |
        | 47 | 1 | 1 | True | 1.00 | True | 12 | 13 | 20 |
        | 48 | 1 | 1 | True | 1.00 | True | 7 | 13 | 20 |
        | 49 | 1 | 1 | False | 0.88 | False | 13 | 14 | 22 |
        | 50 | 1 | 1 | True | 1.00 | True | 14 | 14 | 22 |
        | 51 | 1 | 1 | True | 1.00 | True | 14 | 14 | 22 |
    - 除去第 1 步原始事件（k=0），在 50 个 1 维扰动的 E' 中：判为 new 的只有：step 8, 34, 39, 40, 49，一共 5 次
    - `edge_cov`（覆盖率）几乎一直在 1.00，只有少数 “new” 的时候掉到 0.88 或 0.75。
    - 记忆大小 `mem_edges` 从 8 逐渐长到 14，但增长是阶梯式、比较慢的。
    
    所以：
    
    > 对模型来说，1 维扰动整体上“非常熟悉”，只有极少数 E' 被视为结构明显不一样的新模式。
    > 
    > 
    > 在单维扰动条件下（k=1），HyperMemory 对基准事件表现出高度鲁棒性。
    > 
    > 仅有少数结构上更“边缘”的扰动会被视为 new，触发有限的记忆扩展，从而逐步增强对这一类模式的覆盖能力。
    > 
2. **k=2：覆盖率很高，但一直 new，记忆开始猛长**
    - **结果**
        
        ![Figure_2.png](attachment:8e550395-4625-487d-af20-80984bf43e5f:Figure_2.png)
        
        | step | group | k | is_old | edge_cov | has_cycle | n_active | mem_edges | mem_links |
        | --- | --- | --- | --- | --- | --- | --- | --- | --- |
        | 52 | 2 | 0 | False | 0.50 | False | 3 | 18 | 28 |
        | 53 | 2 | 2 | False | 0.75 | False | 8 | 20 | 32 |
        | 54 | 2 | 2 | False | 0.75 | False | 6 | 22 | 36 |
        | 55 | 2 | 2 | True | 1.00 | True | 12 | 22 | 36 |
        | 56 | 2 | 2 | True | 1.00 | True | 12 | 22 | 36 |
        | 57 | 2 | 2 | False | 0.88 | False | 7 | 23 | 39 |
        | 58 | 2 | 2 | False | 0.75 | False | 11 | 25 | 42 |
        | 59 | 2 | 2 | False | 0.88 | False | 12 | 26 | 45 |
        | 60 | 2 | 2 | True | 1.00 | True | 11 | 26 | 45 |
        | 61 | 2 | 2 | True | 1.00 | True | 11 | 26 | 45 |
        | 62 | 2 | 2 | True | 1.00 | True | 13 | 26 | 45 |
        | 63 | 2 | 2 | False | 0.88 | False | 16 | 27 | 47 |
        | 64 | 2 | 2 | True | 1.00 | True | 12 | 27 | 47 |
        | 65 | 2 | 2 | True | 1.00 | True | 12 | 27 | 47 |
        | 66 | 2 | 2 | False | 0.88 | False | 11 | 28 | 49 |
        | 67 | 2 | 2 | True | 1.00 | True | 15 | 28 | 49 |
        | 68 | 2 | 2 | False | 0.88 | False | 11 | 29 | 52 |
        | 69 | 2 | 2 | True | 1.00 | True | 13 | 29 | 52 |
        | 70 | 2 | 2 | True | 1.00 | True | 11 | 29 | 52 |
        | 71 | 2 | 2 | False | 0.75 | False | 14 | 31 | 55 |
        | 72 | 2 | 2 | True | 1.00 | True | 17 | 31 | 55 |
        | 73 | 2 | 2 | True | 1.00 | True | 14 | 31 | 55 |
        | 74 | 2 | 2 | False | 0.88 | False | 13 | 32 | 57 |
        | 75 | 2 | 2 | False | 0.88 | False | 13 | 33 | 61 |
        | 76 | 2 | 2 | True | 1.00 | True | 16 | 33 | 61 |
        | 77 | 2 | 2 | False | 0.88 | False | 14 | 34 | 65 |
        | 78 | 2 | 2 | True | 1.00 | True | 15 | 34 | 65 |
        | 79 | 2 | 2 | True | 1.00 | True | 14 | 34 | 65 |
        | 80 | 2 | 2 | False | 0.88 | False | 16 | 35 | 67 |
        | 81 | 2 | 2 | True | 1.00 | True | 17 | 35 | 67 |
        | 82 | 2 | 2 | False | 0.88 | False | 11 | 36 | 69 |
        | 83 | 2 | 2 | False | 0.88 | False | 14 | 37 | 71 |
        | 84 | 2 | 2 | True | 1.00 | True | 20 | 37 | 71 |
        | 85 | 2 | 2 | False | 0.88 | False | 9 | 38 | 73 |
        | 86 | 2 | 2 | False | 0.75 | False | 19 | 40 | 77 |
        | 87 | 2 | 2 | True | 1.00 | True | 8 | 40 | 77 |
        | 88 | 2 | 2 | False | 0.88 | False | 17 | 41 | 80 |
        | 89 | 2 | 2 | False | 0.75 | False | 15 | 43 | 84 |
        | 90 | 2 | 2 | True | 1.00 | True | 19 | 43 | 84 |
        | 91 | 2 | 2 | True | 1.00 | True | 16 | 43 | 84 |
        | 92 | 2 | 2 | False | 0.88 | False | 13 | 44 | 87 |
        | 93 | 2 | 2 | True | 1.00 | True | 9 | 44 | 87 |
        | 94 | 2 | 2 | False | 0.88 | False | 20 | 45 | 89 |
        | 95 | 2 | 2 | True | 1.00 | True | 17 | 45 | 89 |
        | 96 | 2 | 2 | True | 1.00 | True | 16 | 45 | 89 |
        | 97 | 2 | 2 | True | 1.00 | True | 23 | 45 | 89 |
        | 98 | 2 | 2 | True | 1.00 | True | 19 | 45 | 89 |
        | 99 | 2 | 2 | True | 1.00 | True | 18 | 45 | 89 |
        | 100 | 2 | 2 | False | 0.75 | False | 23 | 47 | 94 |
        | 101 | 2 | 2 | False | 0.88 | False | 15 | 48 | 96 |
        | 102 | 2 | 2 | True | 1.00 | True | 24 | 48 | 96 |
    - 判 old：27 次
    - 判 new：23 次
    
    对同一个基准事件做 2 维扰动时，系统大概 一半多一点会当成 old，一半多一点会当成 new。
    
    对比 k=1（几乎全部 old），2 维扰动已经明显“介于熟悉和新奇之间”。
    
    ---
    
    - **step 52（k=0，E₂）：**
        - `edge_cov = 0.50`（只有一半的超边能在旧记忆里找到匹配）
        - `is_old = False, has_cycle = False`
        - `n_active = 3`，说明只激活了少量旧边
        - 记忆从 `mem_edges 18 → ...?`（与 group1 结束相比增加了 4 条边、6 个 links）
    
    含义：
    
    - HyperMemory 已经记得了 Group1（k=1）那一类模式；
    - E₂ 与这些模式只有一半的片段是相似的，结构又对不上，所以被当成“新的类”；
    - 于是先为 E₂ 建了一批新的超边和 links。
    
    可以把 E₂ 看成一个“新的原型模式”，但它和旧模式有交叉。
    
    进行一段时间的扰动之后，old/new 交替频率有所下降（old 段稍微长一点），但“完全收敛”的情况并没有出现 —— 模式一直在被扩张。
    
    **记忆体积对比：**k=2 带来了指数级的膨胀
    
    - Group 1 结束时（k=1 实验之后）大概是：
        - `mem_edges ≈ 14`, `mem_links ≈ 22`
    - Group 2 结束时（k=2）：
        - `mem_edges = 48`, `mem_links = 96`
    
    只靠 1 个基准事件 + 50 个 2 维扰动：
    
    - 超边数量增加了 约 34 条（>3 倍）
    - links 数量增加了 约 70 个（>4 倍）
    
    88% 的事件超边都能匹配到记忆，说明和旧模式非常接近；但因为不是 100% 覆盖 + 没有环，所以被全部判为 new；
    
    每次输入都会新建一些超边和链接 → 记忆体积开始明显膨胀。
    
3. **k=3：前几次 new，后面开始“合体成一个 old 模式”**
    - **结果**
        
        ![Figure_3.png](attachment:ab0e2418-1572-4f8e-8b9c-e7aa52761f95:Figure_3.png)
        
        | step | group | k | is_old | edge_cov | has_cycle | n_active | mem_edges | mem_links |
        | --- | --- | --- | --- | --- | --- | --- | --- | --- |
        | 103 | 3 | 0 | False | 0.50 | False | 15 | 52 | 103 |
        | 104 | 3 | 3 | False | 0.75 | False | 12 | 54 | 108 |
        | 105 | 3 | 3 | True | 1.00 | True | 13 | 54 | 108 |
        | 106 | 3 | 3 | False | 0.88 | False | 16 | 55 | 113 |
        | 107 | 3 | 3 | True | 1.00 | True | 23 | 55 | 113 |
        | 108 | 3 | 3 | False | 0.88 | False | 15 | 56 | 117 |
        | 109 | 3 | 3 | True | 1.00 | True | 21 | 56 | 117 |
        | 110 | 3 | 3 | True | 1.00 | True | 14 | 56 | 117 |
        | 111 | 3 | 3 | False | 0.88 | False | 17 | 57 | 120 |
        | 112 | 3 | 3 | False | 0.88 | False | 22 | 58 | 123 |
        | 113 | 3 | 3 | True | 1.00 | True | 14 | 58 | 123 |
        | 114 | 3 | 3 | True | 1.00 | True | 16 | 58 | 123 |
        | 115 | 3 | 3 | False | 0.88 | False | 12 | 59 | 125 |
        | 116 | 3 | 3 | False | 0.88 | False | 17 | 60 | 128 |
        | 117 | 3 | 3 | True | 1.00 | True | 18 | 60 | 128 |
        | 118 | 3 | 3 | False | 0.88 | False | 17 | 61 | 134 |
        | 119 | 3 | 3 | True | 1.00 | True | 15 | 61 | 134 |
        | 120 | 3 | 3 | False | 0.88 | False | 24 | 62 | 140 |
        | 121 | 3 | 3 | True | 1.00 | True | 23 | 62 | 140 |
        | 122 | 3 | 3 | True | 1.00 | True | 15 | 62 | 140 |
        | 123 | 3 | 3 | False | 0.88 | False | 22 | 63 | 143 |
        | 124 | 3 | 3 | True | 1.00 | True | 19 | 63 | 143 |
        | 125 | 3 | 3 | True | 1.00 | True | 14 | 63 | 143 |
        | 126 | 3 | 3 | True | 1.00 | True | 29 | 63 | 143 |
        | 127 | 3 | 3 | True | 1.00 | True | 18 | 63 | 143 |
        | 128 | 3 | 3 | False | 0.62 | False | 17 | 66 | 149 |
        | 129 | 3 | 3 | False | 0.88 | False | 25 | 67 | 152 |
        | 130 | 3 | 3 | False | 0.88 | False | 22 | 68 | 156 |
        | 131 | 3 | 3 | True | 1.00 | True | 25 | 68 | 156 |
        | 132 | 3 | 3 | True | 1.00 | True | 18 | 68 | 156 |
        | 133 | 3 | 3 | True | 1.00 | True | 18 | 68 | 156 |
        | 134 | 3 | 3 | True | 1.00 | True | 27 | 68 | 156 |
        | 135 | 3 | 3 | False | 0.88 | False | 19 | 69 | 160 |
        | 136 | 3 | 3 | False | 0.88 | False | 15 | 70 | 162 |
        | 137 | 3 | 3 | True | 1.00 | True | 28 | 70 | 162 |
        | 138 | 3 | 3 | False | 0.88 | False | 28 | 71 | 165 |
        | 139 | 3 | 3 | True | 1.00 | True | 26 | 71 | 165 |
        | 140 | 3 | 3 | False | 0.88 | False | 23 | 72 | 169 |
        | 141 | 3 | 3 | True | 1.00 | True | 25 | 72 | 169 |
        | 142 | 3 | 3 | False | 0.88 | False | 20 | 73 | 172 |
        | 143 | 3 | 3 | False | 0.88 | False | 27 | 74 | 177 |
        | 144 | 3 | 3 | False | 0.62 | False | 14 | 77 | 182 |
        | 145 | 3 | 3 | True | 1.00 | True | 27 | 77 | 182 |
        | 146 | 3 | 3 | True | 1.00 | True | 18 | 77 | 182 |
        | 147 | 3 | 3 | True | 1.00 | True | 36 | 77 | 182 |
        | 148 | 3 | 3 | True | 1.00 | True | 29 | 77 | 182 |
        | 149 | 3 | 3 | False | 0.75 | False | 25 | 79 | 187 |
        | 150 | 3 | 3 | False | 0.88 | False | 31 | 80 | 190 |
        | 151 | 3 | 3 | False | 0.75 | False | 24 | 82 | 194 |
        | 152 | 3 | 3 | True | 1.00 | True | 22 | 82 | 194 |
        | 153 | 3 | 3 | True | 1.00 | True | 20 | 82 | 194 |
    - **old：27 次**（`is_old=True`）
    - **new：23 次**（`is_old=False`）
    
    比例几乎和 k=2 一模一样：大概 **一半 old、一半 new**。
    
    但有两个显著差异：
    
    1. `edge_cov` 更高：
        - new 时多是 **0.88**，少数 0.75 / 0.62；
        - old 时仍然是 1.00。
    2. `n_active` 的范围明显更大，经常在 **20–30+** 条边之间摇摆，最高到 36。
    
    > 到 k=3 时，虽然扰动更大，但由于记忆已经非常厚，
    > 
    > 
    > 大部分 3 维扰动在局部上依然“很熟”；
    > 
    > old/new 更多是由“是否彻底补齐结构、能不能形成环”决定。
    > 
    
    基准事件 E₃ 的状态
    
    - `edge_cov = 0.50`、`is_old = False`、`n_active = 15`
    - 也就是说，E₃ 和现有记忆有一半超边是共享的，但结构仍然不够形成环 → 被当成 new。
    
    k=3 这 1 条原型 + 50 个扰动 带来的增量：
    
    - 超边：+34 条（48 → 82）
    - links：+98 个（96 → 194）
    
    和 k=2 很像：都是增加 ~30 多条边，但 link 增长更快，体现 连接结构更复杂：
    
    局部熟悉度（coverage, n_active）已经很高，但二值的 “有环/无环” 让 old/new 决策过于猛烈？是否需要一个 soft 的环得分 或结合 coverage 的连续判定，来得到更“人类式”的熟悉度曲线。
    
4. **k=4：4 维扰动已经明显“偏新”**
    - **结果**
        
        ![Figure_4.png](attachment:618a0a98-cc93-424b-b320-6719da00a68f:Figure_4.png)
        
        | step | group | k | is_old | edge_cov | has_cycle | n_active | mem_edges | mem_links |
        | --- | --- | --- | --- | --- | --- | --- | --- | --- |
        | 154 | 4 | 0 | True | 1.00 | True | 24 | 82 | 194 |
        | 155 | 4 | 4 | False | 0.88 | False | 29 | 83 | 198 |
        | 156 | 4 | 4 | True | 1.00 | True | 28 | 83 | 198 |
        | 157 | 4 | 4 | False | 0.88 | False | 24 | 84 | 199 |
        | 158 | 4 | 4 | True | 1.00 | True | 17 | 84 | 199 |
        | 159 | 4 | 4 | False | 0.62 | False | 11 | 87 | 203 |
        | 160 | 4 | 4 | False | 1.00 | False | 13 | 87 | 208 |
        | 161 | 4 | 4 | False | 0.88 | False | 20 | 88 | 212 |
        | 162 | 4 | 4 | False | 0.62 | False | 20 | 91 | 218 |
        | 163 | 4 | 4 | False | 0.88 | False | 13 | 92 | 222 |
        | 164 | 4 | 4 | False | 0.88 | False | 28 | 93 | 229 |
        | 165 | 4 | 4 | True | 1.00 | True | 32 | 93 | 229 |
        | 166 | 4 | 4 | False | 0.88 | False | 13 | 94 | 232 |
        | 167 | 4 | 4 | False | 0.88 | False | 34 | 95 | 236 |
        | 168 | 4 | 4 | False | 0.88 | False | 11 | 96 | 237 |
        | 169 | 4 | 4 | True | 1.00 | True | 23 | 96 | 237 |
        | 170 | 4 | 4 | True | 1.00 | True | 23 | 96 | 237 |
        | 171 | 4 | 4 | False | 0.88 | False | 18 | 97 | 238 |
        | 172 | 4 | 4 | True | 1.00 | True | 10 | 97 | 238 |
        | 173 | 4 | 4 | True | 1.00 | True | 18 | 97 | 238 |
        | 174 | 4 | 4 | False | 0.75 | False | 21 | 99 | 243 |
        | 175 | 4 | 4 | False | 0.88 | False | 24 | 100 | 246 |
        | 176 | 4 | 4 | True | 1.00 | True | 31 | 100 | 246 |
        | 177 | 4 | 4 | True | 1.00 | True | 18 | 100 | 246 |
        | 178 | 4 | 4 | False | 0.62 | False | 17 | 103 | 253 |
        | 179 | 4 | 4 | False | 0.88 | False | 13 | 104 | 255 |
        | 180 | 4 | 4 | False | 0.88 | False | 15 | 105 | 258 |
        | 181 | 4 | 4 | False | 0.75 | False | 24 | 107 | 266 |
        | 182 | 4 | 4 | True | 1.00 | True | 22 | 107 | 266 |
        | 183 | 4 | 4 | False | 0.75 | False | 28 | 109 | 270 |
        | 184 | 4 | 4 | True | 1.00 | True | 33 | 109 | 270 |
        | 185 | 4 | 4 | True | 1.00 | True | 27 | 109 | 270 |
        | 186 | 4 | 4 | False | 0.75 | False | 20 | 111 | 273 |
        | 187 | 4 | 4 | False | 0.88 | False | 34 | 112 | 280 |
        | 188 | 4 | 4 | False | 0.88 | False | 20 | 113 | 284 |
        | 189 | 4 | 4 | False | 0.88 | False | 20 | 114 | 287 |
        | 190 | 4 | 4 | False | 0.88 | False | 28 | 115 | 292 |
        | 191 | 4 | 4 | True | 1.00 | True | 36 | 115 | 292 |
        | 192 | 4 | 4 | True | 1.00 | True | 32 | 115 | 292 |
        | 193 | 4 | 4 | True | 1.00 | True | 43 | 115 | 292 |
        | 194 | 4 | 4 | True | 1.00 | True | 15 | 115 | 292 |
        | 195 | 4 | 4 | True | 1.00 | True | 38 | 115 | 292 |
        | 196 | 4 | 4 | True | 1.00 | True | 16 | 115 | 292 |
        | 197 | 4 | 4 | True | 1.00 | True | 28 | 115 | 292 |
        | 198 | 4 | 4 | False | 0.88 | False | 40 | 116 | 296 |
        | 199 | 4 | 4 | True | 1.00 | True | 29 | 116 | 296 |
        | 200 | 4 | 4 | True | 1.00 | True | 34 | 116 | 296 |
        | 201 | 4 | 4 | False | 0.88 | False | 19 | 117 | 301 |
        | 202 | 4 | 4 | False | 0.88 | False | 36 | 118 | 304 |
        | 203 | 4 | 4 | False | 0.88 | False | 18 | 119 | 308 |
        | 204 | 4 | 4 | True | 1.00 | True | 31 | 119 | 308 |
    
    只看 50 个 k=4 的扰动样本（step 155–204）：
    
    - `is_old=True`：**22 次**
    - `is_old=False`：**28 次**
    
    和 k=2、k=3（都是 27 old / 23 new）相比：k=4 明显“新”的比例更高，说明 4 维扰动已经经常把事件推到现有模式之外。
    
    再看局部熟悉度：
    
    - new 时的 `edge_cov` 取值：{0.62, 0.75, 0.88, 1.00}
        - 平均覆盖率 ≈ **0.84**，局部其实还是挺熟的；
    - old 时 `edge_cov` 一律为 1.00。
    
    也就是说：即便判成 new，4 维扰动在局部超边层面仍然大部分熟悉，
    
    和 E₂、E₃ 不一样：
    
    step 154（k=0, E₄）：`is_old=True, edge_cov=1.00, has_cycle=True, n_active=24`
    
    这说明：在经历了 k=1～3 的那三组实验之后，记忆里已经有足够多的超边和环，使得 E₄ 在第一次出现时就被完全覆盖并形成环。
    
    HyperMemory 已经能在第一次出现时将基准事件 E₄ 判为 old，但随后的 4 维变体中仍有超过一半被视为 new（28/50），这些新事件虽然在局部超边上高度熟悉（平均覆盖率约 0.84），却频繁打破原有的环结构，从而触发了又一轮大规模的超边与 link 扩张（+37 条超边、+114 条 links）。
    
5. **k=5：**
    - **结果**
        
        ![Figure_5.png](attachment:eaf6adf6-aa54-442a-a99f-c5e0e6996deb:Figure_5.png)
        
        | step | group | k | is_old | edge_cov | has_cycle | n_active | mem_edges | mem_links |
        | --- | --- | --- | --- | --- | --- | --- | --- | --- |
        | 205 | 5 | 0 | False | 0.88 | False | 33 | 120 | 312 |
        | 206 | 5 | 5 | True | 1.00 | True | 24 | 120 | 312 |
        | 207 | 5 | 5 | True | 1.00 | True | 32 | 120 | 312 |
        | 208 | 5 | 5 | True | 1.00 | True | 19 | 120 | 312 |
        | 209 | 5 | 5 | False | 0.88 | False | 18 | 121 | 315 |
        | 210 | 5 | 5 | True | 1.00 | True | 19 | 121 | 315 |
        | 211 | 5 | 5 | True | 1.00 | True | 16 | 121 | 315 |
        | 212 | 5 | 5 | True | 1.00 | True | 25 | 121 | 315 |
        | 213 | 5 | 5 | False | 0.75 | False | 18 | 123 | 318 |
        | 214 | 5 | 5 | True | 1.00 | True | 27 | 123 | 318 |
        | 215 | 5 | 5 | False | 0.75 | False | 28 | 125 | 323 |
        | 216 | 5 | 5 | False | 0.88 | False | 20 | 126 | 328 |
        | 217 | 5 | 5 | False | 0.75 | False | 29 | 128 | 333 |
        | 218 | 5 | 5 | False | 0.75 | False | 10 | 130 | 337 |
        | 219 | 5 | 5 | False | 0.88 | False | 15 | 131 | 342 |
        | 220 | 5 | 5 | True | 1.00 | True | 24 | 131 | 342 |
        | 221 | 5 | 5 | False | 0.88 | False | 15 | 132 | 347 |
        | 222 | 5 | 5 | True | 1.00 | True | 30 | 132 | 347 |
        | 223 | 5 | 5 | False | 0.75 | False | 29 | 134 | 354 |
        | 224 | 5 | 5 | True | 1.00 | True | 13 | 134 | 354 |
        | 225 | 5 | 5 | False | 0.75 | False | 19 | 136 | 361 |
        | 226 | 5 | 5 | True | 1.00 | True | 30 | 136 | 361 |
        | 227 | 5 | 5 | True | 1.00 | True | 24 | 136 | 361 |
        | 228 | 5 | 5 | True | 1.00 | True | 29 | 136 | 361 |
        | 229 | 5 | 5 | False | 0.88 | False | 35 | 137 | 365 |
        | 230 | 5 | 5 | False | 0.75 | False | 26 | 139 | 372 |
        | 231 | 5 | 5 | False | 0.88 | False | 26 | 140 | 377 |
        | 232 | 5 | 5 | False | 0.88 | False | 32 | 141 | 381 |
        | 233 | 5 | 5 | True | 1.00 | True | 31 | 141 | 381 |
        | 234 | 5 | 5 | False | 0.75 | False | 28 | 143 | 386 |
        | 235 | 5 | 5 | True | 1.00 | True | 17 | 143 | 386 |
        | 236 | 5 | 5 | False | 0.75 | False | 38 | 145 | 390 |
        | 237 | 5 | 5 | True | 1.00 | True | 34 | 145 | 390 |
        | 238 | 5 | 5 | False | 0.88 | False | 18 | 146 | 394 |
        | 239 | 5 | 5 | False | 0.88 | False | 32 | 147 | 399 |
        | 240 | 5 | 5 | True | 1.00 | True | 38 | 147 | 399 |
        | 241 | 5 | 5 | False | 0.88 | False | 31 | 148 | 406 |
        | 242 | 5 | 5 | False | 0.75 | False | 35 | 150 | 413 |
        | 243 | 5 | 5 | True | 1.00 | True | 32 | 150 | 413 |
        | 244 | 5 | 5 | False | 0.75 | False | 23 | 152 | 418 |
        | 245 | 5 | 5 | True | 1.00 | True | 27 | 152 | 418 |
        | 246 | 5 | 5 | True | 1.00 | True | 33 | 152 | 418 |
        | 247 | 5 | 5 | True | 1.00 | True | 49 | 152 | 418 |
        | 248 | 5 | 5 | False | 0.75 | False | 34 | 154 | 425 |
        | 249 | 5 | 5 | True | 1.00 | True | 20 | 154 | 425 |
        | 250 | 5 | 5 | True | 1.00 | True | 32 | 154 | 425 |
        | 251 | 5 | 5 | False | 0.88 | False | 42 | 155 | 431 |
        | 252 | 5 | 5 | False | 0.88 | False | 34 | 156 | 434 |
        | 253 | 5 | 5 | True | 1.00 | True | 27 | 156 | 434 |
        | 254 | 5 | 5 | True | 1.00 | True | 39 | 156 | 434 |
        | 255 | 5 | 5 | True | 1.00 | True | 25 | 156 | 434 |
    
    只看 50 个 k=5 的样本（step 206–255）：
    
    - `is_old = True`：**26 次**
    - `is_old = False`：**24 次**
    
    局部熟悉度：
    
    - new 时 `edge_cov` 只有两种：**0.75 或 0.88**，没有再掉到 0.62；
    - old 时一律 `1.00`。
    
    即便判成 new，5 维扰动的事件 **75%–88% 的超边都能在记忆里找到匹配**，差别主要来自少数“关键组合”无法闭环。
    
    从 group4 结束到 group5 结束（包含 E₅ 本身）：
    
    - `mem_edges: 119 → 156`（+37）
    - `mem_links: 308 → 434`（+126）
    
    其中，仅 50 个 k=5 扰动 就贡献了约：
    
    - +36 条超边
    - +122 个 links
    
    对比前面几组：
    
    - k=1：+6 edges, +14 links
    - k=2：+34 edges, +70 links
    - k=3：+34 edges, +98 links
    - k=4：+37 edges, +114 links
    - **k=5：+36 edges, +122 links（连接数增幅最大）**
    
    ---
    
    1. **局部熟悉度 vs 二值环判定 —— 可以做“软决策 / 双通路”**
        
        **现象：**
        
        - 很多样本 `edge_cov≈0.88`、`n_active` 很高，但因为没有环 → 直接 new；
        - 甚至出现过 `edge_cov=1.0` 但 `is_old=False` 的情况（k=4, step 160）。
        
        **想法：**
        
        - a.  把“环”从硬规则变成软分数。
            - 定义一个 `cycle_score`：比如激活子图中最长环长度 / 环数 / 环上权重和\
                
                最终 old 概率可以是：
                
                $$
                P(\text{old}) = \sigma(\alpha\cdot \text{edge\_cov} + \beta\cdot \log n_\text{active} + \gamma\cdot \text{cycle\_score})
                $$
                
                这就变成一个 **familiarity（连续）+ recollection（结构）** 的双通路模型，
                
                很贴近人类的理论（也更容易调 AUC）。
                
            
            **让 old/new 决策阈值可学习或自适应**
            
            - 比如根据当前记忆规模（edges/links 数量）动态调整阈值；
            - 或者在 synthetic ROC 实验里直接学一个把 `f_score` 映射到 old/new 的函数。
    2. **记忆爆炸 vs 小扰动高鲁棒 —— 做“容量控制 / 压缩”**
        
        **现象：**
        
        - k=1 几乎不涨；但从 k=2 开始，每多一级扰动都带来 30+ 边、70–120+ links 的增量；
        - 很明显，模型在“中等到强”扰动下会快速变得又大又稠密。
        
        **想法：**
        
        1. **基于活跃度 / 相似度的“边合并 & 压缩”**
            - 统计每条超边被激活的次数（usage count）；
            - 对少用且和其他边高度重叠的超边做合并或删减；
            - 模拟“记忆巩固 + 遗忘”，控制容量。
        2. **两级记忆：episodic vs semantic hypergraph**
            - 短期：先把扰动样本全部记到一个“快速 episodic hypergraph”里；
            - 周期性地，把里面高频模式抽象成更粗的“原型超边”搬到长期 memory，
                
                再清理 episodic 层；
                
            - 这样可以解释 k=2–5 的膨胀现象，也让工程上更可用。
        3. **正则化式的更新策略**
            - 对于 `edge_cov` 已经很高的新样本，可以只增加 link 权重而不是新建边；
            - 只有当 coverage 明显不足（比如 < 0.6）时才允许新建 hyperedges。

# 5. Discussion

- 本文主要以 ROC 是否像人来判断模型的好坏，不是在做“最佳分类器”，而是在做一个 “人类情景记忆的模型”。
- 可以做 old/new 的分类；记忆检索（无法得到原始记忆）；缺失信息预测（准确性保证得并不好）；新颖性，当前行为是不是偏离了历史模式；统计长期高频出现的超边组合 → 预测一个人的习惯，有哪些模式？
- Pattern completion 效果差。
- 作者的超图本质上分成两层结构：
    - 局部是“高阶超边” → 表达一个事件内部的多属性联合关系
    - 全局是“超边之间的连接图（link graph）” → 实际上就是普通图
- 本文只 focus on 判断/记忆一个 event 是否见过，并不能复原整个完整事件，所以 recollection 还是一个全新的领域，但是感觉 recollection 也没有那么强的必要性？
- 而且本文并不针对 LLM，14 年好像还没有。