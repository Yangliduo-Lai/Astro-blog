---
layout: ../../layouts/NotePostLayout.astro
title: 'Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory'
pubDate: 2025-12-20
lastUpdateDate: 2025-12-20
paperDate: 2025-04
category: arXiv
url: http://arxiv.org/abs/2504.19413
tags: [Memory, Mem0, LLM, AI Agents]
---
# 1. Background

1. LLM 受上下文窗口限制。
2. 需要“类人”的持久记忆机制：有选择地记事、整合、更新，在需要时再检索。
3. 本文要解决的核心问题
    - 现有系统（记忆增强模型、RAG、商业记忆平台等）要么记不牢，要么太贵太慢，不适合真正的生产环境。
    - 论文目标：设计一个可落地（低延迟、低 token 开销），又推理力强的长时记忆架构，用来支撑生产级 AI Agent 的长期对话。

# 2. Procedure

## 2.1 Mem0

![image.png](attachment:62c842a1-a805-40e4-a576-a23126ca1d6c:image.png)

总体思路：对每一对新消息做增量处理，抽取候选记忆 → 和旧记忆对比 → 决定增删改。

1. 输入单元：一对消息 $(m_{t−1}, m_t)$
    - $m_t$ 是当前消息，$m_{t−1}$ 是前一条。
2. 构造上下文（给抽取模块）
    - 从数据库取出：
        - **全局摘要 $S$：概括整段对话的语义；**
        - **最近 $m$ 条消息：$\{m_{t−m} … m_{t−2}\}$，$m$ 是窗口长度超参。**
    - **再加上当前消息对 $(m_{t−1}, m_t)$，拼成一个大 prompt：**
        
        $$
        P = (S, \{m_{t−m},…,m_{t−2}\}, m_{t−1}, m_t)
        $$
        
3. 抽取阶段
    - 用一个 LLM 函数 $ϕ(P)$，从 $P$ 中抽取一组“候选记忆”：
        
        $$
        \Omega = {\omega_1, \omega_2, …, \omega_n}
        $$
        
    - 这些 $ωᵢ$ 是用自然语言写的事实/偏好，比如“用户住在旧金山”“是素食者”等。
4. 更新阶段（Update Phase）
    
    对每个 $ωᵢ$：
    
    1. 在向量数据库里检索出 最相似的 $s$ 条旧记忆（用 embedding 做相似度检索）。
    2. 把「候选记忆 + 这些相似记忆」打包给 LLM，通过函数调用（tool call），让 LLM 在四个操作里选：
        - ADD：没有类似事实 → 新增；
        - UPDATE：和旧记忆相关，但新信息更准确/更丰富 → 更新；
        - DELETE：新事实与旧记忆矛盾 → 删除旧记忆；
        - NOOP：已经覆盖或不重要 → 忽略。
    3. 系统执行这些操作，保证记忆库既不冗余、也能随时间演化。

底层记忆检索用稠密向量数据库。

## 2.2 Mem0g

![image.png](attachment:bf5ab47e-8e0f-42ce-b2fd-5d927ca04d30:image.png)

Mem0g 把记忆建成知识图谱，节点是实体，边是关系，更适合做时间推理、关系推理。

1. 图结构定义
    - 图 $G = (V, E, L)$：
        - $V$：实体节点（人、地点、事件……）
        - $E$：关系边，如 *lives_in*、*prefers*
        - $L$：节点类型标签（Person、City、Event 等）
    - 每个 node 包含：类型 + embedding + 创建时间戳。
2. 图记忆抽取流程
    - 第一步：实体抽取器
        - 用 LLM 从对话里抽出需要长期记的实体（人、地点、事件、偏好等），并标注类型。
    - 第二步：关系生成器
        - 再用 LLM 分析这些实体之间的关系，为每对实体生成关系三元组 $(v_s, r, v_d)$，关系类型如 “lives_in / prefers / owns / happened_on”。
3. 图的更新策略
    - 对每个新三元组的 $v_s, v_d$，分别计算源/目标实体的 embedding，去图中找相似度 > 阈值 $t$ 的旧节点：
        - 两个都找不到：新建两个节点，再连一条边；
        - 找到其中一个：复用该节点，另一个新建；
        - 两个都找到：全用已有节点，只要加关系边。
    - 有冲突关系时，会触发 LLM 决策是否把旧关系标记成“失效”，而不是直接删除，以保留时间维度信息。
4. 图记忆的检索
    - 实体中心检索：
        1. 从用户问题里找到**关键实体**（人名、地名、事件等）。
        2. 用语义相似度找到图中对应的节点。
        3. 从这些“锚点”节点出发，把它们的入边、出边都走一遍。
        4. 得到一张包含相关信息的**子图**，作为“上下文”。
    - 语义三元组检索：
        1. 把整条查询编码成一个向量（dense embedding）。
        2. 把图里每个关系三元组也有一个文本表示或向量。
        3. 计算查询向量 vs 所有三元组向量的相似度。
        4. 只返回相似度超过阈值的三元组，并按相似度从高到低排序。

图数据库用 Neo4j；